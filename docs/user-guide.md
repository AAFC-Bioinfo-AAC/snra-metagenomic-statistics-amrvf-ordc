<!-- omit in toc -->
# snra-metagenomic-statistics-amrvf-ordc - USER GUIDE

> ‚ÑπÔ∏è *Feel free to adjust this template to suit your needs, while ensuring that all information necessary for reproducibility is included. See instructions (üëâ in italics) and example content provided under each section header below.*

---

<!-- omit in toc -->
## Table of Contents



- [Overview](#overview)
  - [Workflow diagram](#workflow-diagram)
- [Data](#data)
- [Installation](#installation)
  - [Pre-requisites](#pre-requisites)
  - [Setup Instructions](#setup-instructions)
- [Parameters](#parameters)
- [Usage](#usage)
- [Output](#output)

---

## Overview

> üëâ *Provide a high-level process summary with an optional workflow diagram, created using [Mermaid Diagramming and charting tool](https://mermaid.js.org/) and its [test playground](https://www.mermaidchart.com/play).*

These scripts provide the inforamtion to process and analysis 16S sequencing and metagenomic sequencing reads originating for watershed data and analysed the ability to detect genera related to pathogenic bacteria, antimicrobial resistance genes and virulence genes using both sequencing methods. This data is also analyzed in relation to their accompanying metadata for the watershed samples (physicochemical properties of the water samples, weather, and land use data).

## Workflow diagrams

#### 16S Amplicon Sequence Processing
![Work Flowchart of 16S Processing](Flowchart/GRDI_16S_pipeline.jpeg)
#### Metagenomic Sequence Processing
![Work FlowChart of Metagenomic Data Processing](Flowchart/Wen_Project_1_FlowChart.drawio.png)


---

## Overall Data

> üëâ *Provide information on input data formats, structure, and sources.*

- **16S Sequencing Data**: 
- **Metagenomic Sequencing Data**: 
- **Sample Metadata**:
To download the data, run: `curl -O https://example.com/path/to/dataset1.tar.gz`

---
## 16S Sequencing Read Processing
### Summary

This pipeline processes raw paired-end 16S rRNA sequencing data to generate denoised sequences, assign taxonomy, and construct a phylogenetic tree.

The pipeline includes:

1. Adapter detection and trimming with Atria
2. Importing reads into QIIME2
3. Primer trimming using Cutadapt
4. Quality inspection of demultiplexed reads
5. Denoising with DADA2
6. Exporting feature tables and representative sequences
7. Taxonomy assignment using a Greengenes2 reference
8. Phylogenetic tree construction


### Data
This pipeline requires paired-end 16S reads and a reference database.

Raw FASTQ reads: Paired-end sequences in .fastq.gz format generated by Illumina MiSeq (ENA Project PRJEB102733).
Reference database: Greengenes2 sequences and taxonomy files (.fasta and .tsv).
To download the reference data, run: wget https://ftp.microbio.me/greengenes_release/2022.10

### Installation

#### Pre-requisites

- Conda
- Atria
- Cutadapt
- QIIME2 2023.7
- Python 3.9+
- Recommended OS: Linux

#### Setup Instructions

- Clone the repository:

```bash
git clone https://github.com/AAFC-BICoE/SNRA-Metagenomic-Statistics-AMRVF-ORDC/
cd SNRA-Metagenomic-Statistics-AMRVF-ORDC
```

- Create the Conda environment

```bash
conda env create -f your-repo/config/environment.yml
conda activate qiime2-2023.7
```
Ensure Atria and Cutadapt are installed and available in your PATH.

### Parameters

> üëâ *List all configuration options in a clear and consistent format. Include descriptions, expected values, and defaults if applicable.*  

| Parameter          | Description                                         | Type    | Default    | Example                 |
|--------------------|-----------------------------------------------------|---------|------------|-------------------------|
| `RAWDATA_DIR`   | Folder containing raw FASTQ reads           | Path    | `data`     | `/path/to/Raw_data`         | `./data/fastq`|
| `WKDIR`  | Working directory   | Path    | `/path/to/wdir`  | `./results` |
| `REF_DIR` |  Reference database location  | Path | `/path/to/Reference/greengene2`     | `./reference/greengene2`                 |
| `MANIFEST` | Manifest CSV file for QIIME2 import | File | `${WKDIR}/manifest.csv` | './manifest.csv' |
| `CONDA_ENV` | Conda environment name | String | `qiime2-2023.7` | `qiime2-2023.7` |
| `CPUS` | Number of CPU threads | Integer | `16` | `32` |
| `TRIM_LEFT_F/R` | Bases trimmed from 5‚Äô end during DADA2 denoise | Integer | `0` | `17` |
| `TRUNC_F/R` | Bases to truncate at 3‚Äô end during DADA2 denoise | Integer | `229/187` | `250/200` |
| `FWD` | Forward primer sequence | String | `GTGYCAGCMGCCGCGGTAA` | `N/A` |
| `REV` | Reverse primer sequence | String | `CGYCAATTYMTTTRAGTTT` | `N/A` |

Notes:

- All paths can be relative or absolute.
- If not specified, default values will be used.  
- Adjust truncation and trim lengths after inspecting the demux summary .qzv.
---

### Step-by-step Usage
#### Step 0: Activate Conda Environment
```
conda activate qiime2-2023.7
mkdir -p ${WKDIR}/logs ${WKDIR}/qiime2_output
cd ${WKDIR}
```
#### Step 1: Adapter Detection & Trimming (Atria)
```
cd ${RAWDATA_DIR}
atria --detect-adapter -r *_R1.fastq.gz -R *_R2.fastq.gz > ${WKDIR}/logs/atria_detect.txt 2>&1 || true

mkdir -p ${WKDIR}/16S_atria_trimmed_sequence_file
atria -a AGATCGGAAGAGCACA -A AGATCGGAAGAGCGTC \
      -r *_R1.fastq.gz -R *_R2.fastq.gz \
      -o ${WKDIR}/16S_atria_trimmed_sequence_file \
      > ${WKDIR}/logs/atria_trim.log 2>&1
```
#### Step 2: Import to QIIME2
```
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path ${MANIFEST} \
  --output-path qiime2_output/16S_PE.qza \
  --input-format PairedEndFastqManifestPhred33 \
  &> ${WKDIR}/logs/qiime_import.log
```
#### Step 3: Primer Trimming (Cutadapt)
```
cd ${WKDIR}/qiime2_output
```
#### Step 3a: Trim primers
```
qiime cutadapt trim-paired \
  --i-demultiplexed-sequences 16S_PE.qza \
  --p-cores ${CPUS} \
  --p-front-f "${FWD}" \
  --p-front-r "${REV}" \
  --o-trimmed-sequences 16S_PE.primer.trimmed.qza \
  --verbose &> ${WKDIR}/logs/primer_trimming_step1.log
```
#### Step 3b: Trim reverse-complement primers
```
REVCOMP_FWD="TTACCGCGGCKGCTGRCAC"
REVCOMP_REV="AAACTAAAKRAATTRCG"

qiime cutadapt trim-paired \
  --i-demultiplexed-sequences 16S_PE.primer.trimmed.qza \
  --p-cores ${CPUS} \
  --p-front-f "${REVCOMP_FWD}" \
  --p-front-r "${REVCOMP_REV}" \
  --o-trimmed-sequences 16S_PE.primer.trimmed2.qza \
  --verbose &> ${WKDIR}/logs/primer_trimming_step2.log
```
#### Step 4: Inspect Demux Quality
```
qiime demux summarize \
  --i-data 16S_PE.primer.trimmed2.qza \
  --o-visualization 16S_PE.primer.trimmed2.qzv \
  &> ${WKDIR}/logs/demux_summary.log
```
Open .qzv in qiime tools view or upload to view.qiime2.org

#### Step 5: DADA2 Denoising
```
mkdir -p DADA2_denoising_output
TRIM_LEFT_F=0
TRIM_LEFT_R=0
TRUNC_F=229
TRUNC_R=187

qiime dada2 denoise-paired \
  --i-demultiplexed-seqs 16S_PE.primer.trimmed2.qza \
  --p-trim-left-f ${TRIM_LEFT_F} \
  --p-trunc-len-f ${TRUNC_F} \
  --p-trim-left-r ${TRIM_LEFT_R} \
  --p-trunc-len-r ${TRUNC_R} \
  --p-n-threads ${CPUS} \
  --output-dir DADA2_denoising_output \
  --verbose &> ${WKDIR}/logs/DADA2_denoising.log
```
#### Step 6: Export DADA2 Outputs
```
qiime metadata tabulate \
  --m-input-file DADA2_denoising_output/denoising_stats.qza \
  --o-visualization DADA2_denoising_output/denoising_stats.qzv

qiime tools export \
  --input-path DADA2_denoising_output/representative_sequences.qza \
  --output-path representative_sequences

qiime tools export \
  --input-path DADA2_denoising_output/table.qza \
  --output-path feature-table

biom convert -i feature-table/feature-table.biom -o feature-table/feature-table.tsv --to-tsv
```
#### Step 7: Taxonomy Assignment
```
REF_FASTA="${REF_DIR}/ref_seqs.fasta"
REF_TAX="${REF_DIR}/ref_taxonomy.tsv"
REF_PREFIX="greengenes2"

qiime feature-classifier extract-reads \
  --i-sequences "${REF_FASTA}" \
  --p-f-primer "${FWD}" \
  --p-r-primer "${REV}" \
  --p-min-length 300 \
  --p-max-length 600 \
  --o-reads "${REF_PREFIX}.V4-V5.qza"

qiime feature-classifier fit-classifier-naive-bayes \
  --i-reference-reads "${REF_PREFIX}.V4-V5.qza" \
  --i-reference-taxonomy "${REF_TAX}" \
  --o-classifier "${REF_PREFIX}.classifier_V4-V5.qza"

qiime tools import \
  --type 'FeatureData[Sequence]' \
  --input-path representative_sequences/dna-sequences.fasta \
  --output-path representative_sequences.qza

qiime feature-classifier classify-sklearn \
  --i-classifier "${REF_PREFIX}.classifier_V4-V5.qza" \
  --i-reads representative_sequences.qza \
  --o-classification rep_fasta.classified.gg2_V4-V5.qza
```
#### Step 8: Phylogenetic Tree Construction

```
 qiime phylogeny align-to-tree-mafft-fasttree \ --i-sequences DADA2_denoising_output/representative_sequences.qza \ --output-dir phylogenetic_tree \ --p-n-threads ${CPUS}
```
### Output

> üëâ *Describe output format, location, naming convention, and purpose.*

Output files include:

| File/Folder	| Description |
|------------|--------------|
| 16S_PE.primer.trimmed2.qzv |	Demultiplexed and primer-trimmed reads summary |
| DADA2_denoising_output |	Denoised sequences and feature tables |
| feature-table/feature-table.tsv |	Exported feature table in TSV format |
| representative_sequences/dna-sequences.fasta |	Representative sequences of ASVs |
| rep_fasta.classified.gg2_V4-V5/	| Taxonomy assignments in TSV format |
| phylogenetic_tree/ |	Phylogenetic tree QZA and related visualizations |
| logs/	| Log files for all steps |

---
## Metagenomic Read-Based Detection of Antimicrobial Resistance and Virulence Genes

### Summary
### Data
Trimmed (using Trimmomatic) metagenomic reads for each of the samples in compressed fastq format.

### Installation

#### Pre-requisites

- Conda
- fastqc
- multiqc
- bowtie2
- samtools
- bedtools
- kma
- Python 3.9+
- Recommended OS: Linux

#### Setup Instructions

- Clone the repository:

```bash
git clone https://github.com/AAFC-BICoE/SNRA-Metagenomic-Statistics-AMRVF-ORDC/
cd SNRA-Metagenomic-Statistics-AMRVF-ORDC
```

- Create the Conda environment

```bash
conda env create -f conda_env/multifastqc.yaml
conda env create -f conda_env/metareadcounts.yaml
```
Download VFDB (http://www.mgc.ac.cn/VFs/download.htm; lastupdate: Fri Dec 1 19:30:02 2023)
 and MegaRESv3 (https://www.meglab.org/megares/download/) and put them in your PATH

### Parameters
The bash scripts have three components:
1. The main script: This has the actual command for software that I want to run on the samples.

```
#!/bin/bash -l
#starts calling bash with the HPC specific details

#initating conda 
source ~/miniconda3/etc/profile.d/conda.sh
#activating conda environment with fastqc (or other software you are using) installed
conda activate multifastqc

#calling the variable from the assisting script to bring sample information into script
line=$1

#the actual code/software I want to execute on the sample
fastqc "$line"_R1.atria.fq.gz
fastqc "$line"_R2.atria.fq.gz
```
2. The assisting script: This ensures that all the samples run in a separate job and using the main script.
```
#calling bash
#!/bin/bash -l
#loop the command to run the main script through a list of samples
cat "list_MG_samples.txt" | while IFS= read -r line; do
    echo "Processing line: $line"
    sbatch fastqc.sh "$line"
done
```
3. The list of samples I want to run
```
SN005-20160524
SN005-20160606
SN005-20160704
 ```

---

### Step-by-step Usage
### Read_Quality_Control
1. Run fastqc on all the metagenomic reads (in compressed fastq format) (*fastqc.sh* and *assisting_fastqc.sh*).
2. Use MultiQC to get the results from fastqc in one report (*multiqc.sh*).

### Read-based_AMR_VF_Detection
1. Use Bowtie2 and SAMtools to map metagenomic reads to the MEGARes database (*mappingread.sh*).
2. Assisting script for 1 to read map for every sample listed in the accompanying txt file (one sample per line) (*assisting_mappingread.sh*).
3. Use Bowtie2 and SAMtools to map metagenomic reads to the VFDB database (*VFDB_mappingread.sh*).
4. Assisting script for 3 to read map for every sample listed in the accompanying txt file (*assisting_VFDB_mappingread.sh*).
5. Use the experimentally proven VFDB database with read mapping with Bowtie2 and SAMtools (*VFDB_exp_mappingreads.sh*).
6. Assisting script for 5 to read map for every sample listed in the accompanying txt file (*assisting_VFDB_exp_mappingreads.sh*).
7. Map reads for MEGARes using KMA (*mapping_AMR_KMA.sh*).
8. Assisting script for 7 to read map for every sample listed in the accompanying txt file (*assisting_mapping_AMR_KMA.sh*).
9. Map reads for VFDB using KMA (*mapping_VFDB_KMA.sh*).
10. Assisting script for 9 to read map for every sample listed in the accompanying txt file (*assisting_mapping_VFDB_KMA.sh*).

### Output
A list of the AMR genes and VFs present in each metagenomic sample.
| File/Folder	| Description |
|------------|--------------|
| output/"$line" | TXT file with the table of AMR genes from MegaRES mapped to a particular set of reads (specified in the variable $line in the bash scripts) |
| KMA_output/"$line"_VFDB |	TXT File with the table of virulence genes from VFDB mapped to a particular set of reads ( specified in the variable $line in the bash scripts) |
---

## Metagenomic Read-Based Detection of Antimicrobial Resistance and Virulence Genes

### Summary
### Data
Trimmed (using Trimmomatic) metagenomic reads for each of the samples in compressed fastq format.

### Installation

#### Pre-requisites

Reads are first taxonomically characterised using the custom Snakemake pipeline found here: [snra-metagenomic-statistics-amrvf-ordc-report](https://github.com/AAFC-Bioinfo-AAC/snra-metagenomic-statistics-amrvf-ordc-report)

- Conda

- Python 3.9+
- Recommended OS: Linux

#### Setup Instructions

- Clone the repository:

```bash
git clone https://github.com/AAFC-BICoE/SNRA-Metagenomic-Statistics-AMRVF-ORDC/
cd SNRA-Metagenomic-Statistics-AMRVF-ORDC
```

- Create the Conda environment

```bash
conda env create -f conda_env/multifastqc.yaml
conda env create -f conda_env/metareadcounts.yaml
```


### Parameters
The bash scripts have three components:
1. The main script: This has the actual command for software that I want to run on the samples.

```
#!/bin/bash -l
#starts calling bash with the HPC specific details

#initating conda 
source ~/miniconda3/etc/profile.d/conda.sh
#activating conda environment with fastqc (or other software you are using) installed
conda activate multifastqc

#calling the variable from the assisting script to bring sample information into script
line=$1

#the actual code/software I want to execute on the sample
fastqc "$line"_R1.atria.fq.gz
fastqc "$line"_R2.atria.fq.gz
```
2. The assisting script: This ensures that all the samples run in a separate job and using the main script.
```
#calling bash
#!/bin/bash -l
#loop the command to run the main script through a list of samples
cat "list_MG_samples.txt" | while IFS= read -r line; do
    echo "Processing line: $line"
    sbatch fastqc.sh "$line"
done
```
3. The list of samples I want to run
```
SN005-20160524
SN005-20160606
SN005-20160704
 ```

---

### Step-by-step Usage

### Output
A list of the AMR genes and VFs present in each metagenomic sample.
| File/Folder	| Description |
|------------|--------------|
| output/"$line" | TXT file with the table of AMR genes from MegaRES mapped to a particular set of reads (specified in the variable $line in the bash scripts) |
